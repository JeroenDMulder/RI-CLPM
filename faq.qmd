---
title: "Frequently Asked Questions"
output: 
  html_document:
    toc:  true
    toc_float: true
bibliography: references-faq.bib
---

Below you can find a list of frequently asked questions, organized by topic, that reach us via email. Click the question to see our response.

### Including covariates
::: {.callout-note icon=false collapse="true" appearance="simple" title="How do I include *time-varying* covariates with the RI-CLPM?"}

The inclusion of a single additional time-varying covariate (TVC) $Z$ is commonly done similarly to how “regular” $X$ and $Y$ outcomes are treated in the RI-CLPM; hence, rather than a bivariate RI-CLPM you would specify a tri- (or more-variate) RI-CLPM. As such, you decompose the TVC in within-components (e.g. $wz1$, $wz2$, etc.) and a between-component (a random intercept for $Z$; e.g. $RI_{z}$) and model these components separately. However, if you want to control for many TVCs, this approach can quickly become unwieldly, leading to large statistical models that rely on many causal and statistical assumptions, and that can be hard to estimate. For researchers who want to adjust for a larger set of time-varying covariates, it might be worthwhile to consider alternative modeling approaches that have been proposed in the causal inference literature, such as those based on propensity scores. 
:::

::: {.callout-note icon=false collapse="true" appearance="simple" title="Is it possible to run an RI-CLPM with three (or more) outcomes?"}

Yes, it is statistically possible to run a “trivariate” RI-CLPM and empirical researchers have done so, see for example @van_lissa_role_2019, @flouri_developmental_2019, and @hygen_longitudinal_2022. We don’t provide model code here for this mode, but extension to a trivariate RI-CLPM should be relatively straight forwards. That is, all variables should be decomposed into between- (random intercepts) and within-components, and relevant lagged effects, as well as (residual) variances and covariances, should be included in the model.
:::

### Moderation and mediation
::: {.callout-note icon=false collapse="true" appearance="simple" title="Is it possible to specify a moderator within the RI-CLPM?"}

There are various approaches for studying moderation within the RI-CLPM, depending on the measurement level of the moderator variable. Moderation by a time-invariant, categorical variable can be investigated using a multiple group RI-CLPM, as described in Extension 2 of @mulder_three_2021. Moderation by a time-varying, continuous variable can be investigating by creating latent interactions of the moderator $\times$  within-components, or the moderator $\times$ random intercept factor(s). See @ozkok_interaction_2022 and @speyer_testing_2023 for detailed information on how to this. 

Due to the high computational burden that the inclusion of a continuous time-varying moderator places on the estimation, @ozkok_interaction_2022 make use of a Bayesian estimator. Their supplemental materials, including the Mplus model syntax, can be found at [https://journals.sagepub.com/doi/suppl/10.1177/10944281211043733](https://journals.sagepub.com/doi/suppl/10.1177/10944281211043733). They note that currently only Mplus supports the use of latent interactions as used here. 
:::

::: {.callout-note icon=false collapse="true" appearance="simple" title="Is it possible to test for mediation effects in the RI-CLPM?"}

While it is statistically possible to include a third time-varying covariate into the RI-CLPM (which can be used to investigate mediation at the within-person level), there are multiple theoretical concerns that complicate the interpretation of estimates related to mediation. Researchers are strongly advised to give these concerns due consideration when interested in studying mediation using the RI-CLPM. 

First, there are multiple options for defining a direct effect, and it might not be straightforward which option is appropriate for a particular research question. That is, there are multiple paths not through the mediator variable $M$ that represent an effect of $X$ on a $Y$ at a later occasion. For example, is the direct effect only the lag-2 effect $X_{1} \rightarrow Y_{3}$, or is the combination of the effects $X_{1} \rightarrow Y_{2} \rightarrow Y_{3}$, $X_{1} \rightarrow X_{2} \rightarrow Y_{3}$ *and* $X_{1} \rightarrow Y_{3}$? 

Second, mediation analysis is often causal in nature, as you want to know the mechanism by which a variable $X$ influences another variable $Y$. For a causal interpretation of the statistical estimates, you need to carefully evaluate the causal identification assumptions (i.e., exchangeability, consistency, and positivity), and rely on the statistical assumptions that implied by the RI-CLPM (e.g., linearity, multivariate normality). Evaluation of these assumptions can be quite challenging, and you might find that your targeted causal mediation effect is not identified. Interested readers are referred to @keele_causal_2015 for a short introduction to these assumptions in the context of mediation analysis. 
:::


### Standardization
::: {.callout-note icon=false collapse="true" appearance="simple" title="How should I interpret the standardized cross-lagged and autoregressive parameters?"}

In the RI-CLPM, the standardized effects are reflective/representative of how much within-person variance in $y_{t}$ is *uniquely* explained (i.e., not also explained by other predictors) by the predictor $x_{t-1}$. Please note that this does not imply that one can make a one-on-one comparison with the percentage of explained variance. However, the standardized effects can be used to compare which effect is relatively stronger [@schuurman_how_2016].
:::

::: {.callout-note icon=false collapse="true" appearance="simple" title="How do standardized cross-lagged and autoregressive parameters compare to explained variance?"}

The standardized lagged parameters are not equal to the (squared) semipartial correlation. Only under special circumstances, a standardized regression coefficient is equal to the pairwise correlation between the outcome and predictor, and the square of the standardized regression coefficient would then be the explained variance ($R^{2}$). This only applies in the case of (a) a simple regression, where there is only one predictor in the model, or (b) a multiple regression where the predictors are independent of each other. In the RI-CLPM, however, the multiple predictors are not independent of each other, and therefore the standardized regression coefficients are not equal to the pairwise correlation, (semi)partial correlation, or the unique explained variance. 

However, the standardized coefficient is closely related to the semipartial correlation, as demonstrated in footnote 3 of @schuurman_how_2016. The standardized coefficient is expressed in terms of pairwise correlations in the first equation there, and the semipartial correlation expressed in terms of pairwise correlations in the second equation. They are very similar, but there is a subtle difference in the denominator.
 
So, the semipartial correlation and standardized coefficient are not equal, but we can see that if the semipartical correlation for one predictor is larger than for another predictor, this will also be the case for the standardized coefficients of these predictors. The square of the semi-partial correlation is the *unique* explained variance, so we also know that the predictor with the largest standardized coefficient, will also have the largest *unique* explained variance. 

*Answer by [dr. Noémi Schuurman](https://www.uu.nl/staff/NKSchuurman).*
:::

::: {.callout-note icon=false collapse="true" appearance="simple" title="How can I constrain the *standardized* parameters to be invariant over time?"}

While the lagged parameters can be constrained to be invariant over time, this does not imply that the standardized parameters will be invariant over time as well. The reason for this is that a standardized parameter is a function of the unstandardized parameter, and of the standard deviations of the predictor and the outcome variable, $\beta_{standardized} = \frac{SD(x)}{SD(y)}\beta$. Since the variances of the within-components *themselves* are not constrained to be invariant over time, the standard deviations of the predictor and the outcome variable for the lagged effects can vary over time. Therefore, the standardized lagged effects can vary even while the unstandardized lagged effects are constrained to be equal over time.

To make the standardized lagged parameters time invariant, the within-person components need to have a variance of 1 at every occasion. In that case, the lagged parameters are already the standardized lagged parameters, and it becomes
possible to impose time-constraints on them. At the first wave, the variances of the within-components can be set directly as these variables are exogenous. However, for $t > 1$, the variances of the within-components are functions of
the lagged parameters, and the covariance between the lagged predictors. Specifically, using *the path tracing rules* [@wright_method_1934] and assuming the variance of lagged within-component is in fact 1, the variance of $wx_{it}$ can be expressed as $$Var[wx_{it}] = \alpha^{2}_{t} + \gamma^{2}_{t} + 2 \alpha_{t} \gamma_{t} Cov[wx_{i,t-1}, wy_{i,t-1}] + Var[u_{it}]$$ where $\alpha_{t}$ is the autoregressive effect of $wx$, $\gamma{t}$ is the cross-lagged effect from $wy_{i,t-1}$ to $wx_{it}$, and $u_{Xit}$ is the residual of $wx$. So, the variance of $wx_{it}$ itself can be set to 1 by imposing a constrain on the residual variance $Var[u_{it}]$, that is $$Var[u_{it}] = 1 - (\alpha^{2}_{t} + \gamma^{2}_{t} + 2 \alpha_{t} \gamma_{t} Cov[wx_{i,t-1}, wy_{i,t-1}])$$. 

The final quantity that we need to compute is the covariance (here also the correlation) between the two lagged within-components,  $Cov[wx_{i,t-1}, wy_{i,t-1}]$. At wave 1, this is simply a model parameter (i.e., the covariance between the within-components can be estimated directly). For $t > 1$, this covariance is a function of the lagged coefficients, the variances of the lagged within-components, and the covariance between the residuals at the preceding occasion. Again, using the path tracing rules and assuming the variances of lagged within-components are in fact 1, it can be expressed as $$Cov[wx_{it}, wy_{it}] = \alpha_{t} \gamma_{t} + \beta_{t} \delta_{t} + \alpha_{t} \delta_{t} Cov[wx_{i,t-1}, wy_{i,t-1}] + \beta_{t} \gamma_{t} Cov[wx_{i,t-1}, wy_{i,t-1}] + Cov[u_{Xit}, u_{Yit}]$$ where $\delta_{t}$ is the autoregressive effect of $wy$, $\beta_{t}$ is the cross-lagged effect from $wx_{i,t-1}$ to $wy_{it}$, and $u_{Yit}$ is the residual of $wy$. 

To impose such constraints in Mplus or *lavaan*, we thus first need to compute the covariance (i.e., correlation) between the within-components at each occasion. Then, these can be used to constrain the residual variances of the within-components in such a way that the variances of the within-person components equal 1. Syntax has been added to this website to specify this model in [Mplus](https://jeroendmulder.github.io/RI-CLPM/mplus.html#The_RI-CLPM) and [lavaan](https://jeroendmulder.github.io/RI-CLPM/lavaan.html#The_RI-CLPM). Note that in this model, the factor loadings that link the observed variables to the within-components are not fixed to 1 as is usually done, but they are estimated freely. 

*Answer by [prof. dr. Ellen L. Hamaker](https://www.uu.nl/staff/ELHamaker).*
:::


### Non-continuous outcomes

::: {.callout-note icon=false collapse="true" appearance="simple" title="Can I run the RI-CLPM with binary/categorical/count outcomes?"}

With Mplus version 8.7 and later, it is possible to estimate the RI-CLPM for binary and ordinal variables as well [@asparouhov_residual_2021]. Compared to the RI-CLPM for continuous variables, there are two important differences: 

- A Bayesian estimator or WLSMV estimator (with theta parametrization) is needed. This can be specified by specifying either `ESTIMATOR = BAYES;` or `ESTIMATOR = WLSMV;` in the `ANALYSIS` command, as well as `PARAM = THETA;` for the WLSMV estimator. 
- The variances and residual variances of the within-components are fixed to 1, as is standard when using the probit-model in Mplus for categorical data analysis. These can be freely estimated in principle, but generally require larger sample sizes, and are prone to empirical non-identification. Several strategies for (partly) freeing up these variances are discussed in @asparouhov_residual_2021. 

The interested reader is referred to @asparouhov_residual_2021 for more details.
:::


### Power
::: {.callout-note icon=false collapse="true" appearance="simple" title="How do I perform a power analysis for the RI-CLPM?"}

`powRICLPM` is an R-package that performs a power analysis for the RI-CLPM in a simple and user-friendly way. It implements the strategy as proposed by @mulder_power_2023, and includes various extensions such as the inclusion of measurement error (leading to the stable trait autoregressive trait state model by @collins_traitstate_2001, and multiple constraints over time. `powRICLPM` is available from the Comprehensive R Archive Network (CRAN). More information can be found at [https://jeroendmulder.github.io/powRICLPM/](https://jeroendmulder.github.io/powRICLPM/).
:::


### CLPM v. RICLPM
::: {.callout-note icon=false collapse="true" appearance="simple" title="Why are the autoregressive effects in the RI-CLPM typically smaller than in the CLPM?"}

The autoregressive effects in the CLPM and the RI-CLPM capture two distinct phenomena. In the traditional CLPM, the autoregressive effects capture both within- and between-unit effects, and it can be interpreted as rank-order stability. In the RI-CLPM, the stable, between-person variance is separated from the within-person variance such that the autoregressive effects only capture within-person carry-over. In other words, in the RI-CLPM the autoregressive effects are typically smaller because the stable, trait-like stability is not captured anymore by the autoregressive effects (as in the CLPM), but by the random intercepts.
:::

::: {.callout-note icon=false collapse="true" appearance="simple" title="Is it a bad sign that the standard errors are typically larger in the RI-CLPM than in the CLPM?"}

No, this is to be expected because the RI-CLPM is a more complex model than the CLPM. Therefore, the point estimates are less certain, but this does not imply that the estimates are biased and the model does not give us any insight in the underlying mechanism under study. In contrast, the RI-CLPM is likely less biased than results from the CLPM because the RI-CLM accounts for stable, unobserved factors that create lasting between-person differences, which can create spurious empirical relationships between the constructs under investigation when not properly accounted for.
:::

### Growth and development
::: {.callout-note icon=false collapse="true" appearance="simple" title="How can the RI-CLPM incorporate growth over time?"}

The RI-CLPM estimates grand means at each time point. If these are constrained to be time-invariant, this would imply that on average there is no change. However, if these constraints cannot be imposed on the model, this means that on average there is some kind of change (e.g., growth, decline, U-shape, sudden jump between two waves, etc.). In this case, the model implies that **every person** is modeled to have the exact same underlying trend over time, but at a constant deviation from the average trend (as captured by the random intercept factor). Hence, instead of talking about constant means over time, one would have to talk about constant deviations from an average trend.

In the latent growth curve model (LGCM) and its extension, the latent curve model with structured residuals (LCM-SR), it is assumed that individual have the same kind of trend (e.g., a linear or quadratic trend), but there can be individual differences in the parameters of this trend; as a result, the differences between individuals change over time (i.e., they may increase or decrease). When the variance of the slope components (i.e., the slope factor of both $X$ and $Y$ in the bivariate case) is fixed to zero, the LGCM and LCS-SR become special cases of the RI-CLPM; if the grand means in the RI-CLPM are fixed to be invariant over time, then this is a special case of the LCM-SR [@usami_unified_2019].
:::

### Response to @orth_testing_2021

Lately, we have received numerous questions about statements regarding the use and appropriateness of the CLPM and RI-CLPM in "Testing Prospective Effects in Longitudinal Research: Comparing Seven Competing Cross-Lagged Models" by @orth_testing_2021. In our opinion, numerous conclusions herein are incorrect. Below we elaborate on some of their most prominent conclusions. For another reaction to this article, see [https://replicationindex.com/2020/08/22/cross-lagged](https://replicationindex.com/2020/08/22/cross-lagged/).

::: {.callout-note icon=false collapse="true" appearance="simple" title="The RI-CLPM is not suited for studying prospective between-person effects, whereas the CLPM is."}

On page 1026, @orth_testing_2021 state that the RI-CLPM does not allow for the testing of prospective between-person effects because "(...) *the random intercept factors provide information only about correlational associations between the constructs* (...)*, but not about time-lagged (i.e, longitudinal) and directional between-person effects.*" It is true that the RI-CLPM separates stable, between-person differences from temporal, within-person fluctuations. Only the latter allow one to look at prospective effects over time, while the stable between-person differences have no particular time-order.

The reasoning that @orth_testing_2021 seem to follow is this: If one is interested in trait-changes, we should not separate the stable trait components from the temporary fluctuations, as the first does not allow for the study of prospective effects and are not of interest because they are entirely stable, while the latter only contain state-like fluctuations that are less interesting to researchers who want to study in trait-changes. @orth_testing_2021 seem to consider both components separately not to be of interest, but nevertheless argue that a blend of both components is of key interest. We disagree with this reasoning.

Researchers who want to use prospective effects to study certain psychological processes, should make sure that their measurements are obtained at the time scale at which they believe the process of interest operates. If the trait-changes of interest are assumed to take place from one year to the next, then measuring yearly over several years should capture the fluctuations of interest within persons over the time span covered by the study. If trait-changes are assumed to take place at a less fine time scale, such as from decade to decade, this implies researchers should obtain data measured once per decade, for several decades. 

Even if the stable, between-person differences are not of interest, these nevertheless need to be separated from the within-person fluctuations. The stable mean differences between persons are often referred to as trait differences, but may also be conceptualized as resulting from stable confounders, such as stable genetic and environmental factors that affect our measurements.   

In sum, the focus should be on how the constructs are measured, specifically at what time scale they are measured. By definition, the random intercepts in the RI-CLPM capture variance that is stable over the duration of the study, which is why—from a data analytical perspective—these are referred to as traits. What remains is variance within persons over time, which is why—again from a data analytical perspective—this is referred to as state-like. These trait-like between-person differences and state-like, within-person fluctuations need not coincide perfectly with the trait-state distinction made by substantive researchers. Nevertheless, it is essential to separate these two sources, regardless of what they are called.
:::

::: {.callout-note icon=false collapse="true" appearance="simple" title="The RI-CLPM is better suited for short-term studies because it cannot detect sustained prospective effects."}

The characterization of the lagged effects as short- or long-term depends on the time scale at which the measurements are made. When using annual data, lagged effects capture the fluctuation from year to year; when dealing with data that were obtained every decade, the within-person fluctuations will concern the changes from decade to decade. It is all relative to how the data were measured, and even when we are focusing on trait changes by measuring people once every 10 years, for say 40 years, there will still be stable between-person differences between individuals that need to be controlled for.

Hence, the need to decompose the observations into a stable between-person component and temporal within-person components is independent of the time scale at which measurements were obtained.
:::

::: {.callout-note icon=false collapse="true" appearance="simple" title="There should be a match between the type of research question asked and the model used: The CLPM is for the analysis of between-person prospective effects whereas the RI-CLPM should be used for within-person prospective effects."}

We agree with the authors in so far that there should be a match between the research question and the statistical model used. However, the critical distinction here is not whether one is interested in within-person or between-person prospective effects (as argued above, the RI-CLPM can capture trait-changes depending on the time scale at which measurements are gathered). Rather, we should distinguish between descriptive, predictive, and causal research questions [@hamaker_description_2020]. The CLPM is suitable for predictive research questions: e.g., "Who is at risk for heightened $X$?" and "Who should get an intervention to reduce $Y$?". However, for answering causal research questions, other models should be used, because the CLPM does not control for stable, between-person difference. This is problematic as failing to properly account for such confounding effects can lead to finding spurious lagged effects, a failure to find true relationships, or more generally, biased estimates [@hamaker_critique_2015].
:::

::: {.callout-note icon=false collapse="true" appearance="simple" title="The parameters from the CLPM tend to have smaller standard errors than the parameters from the RI-CLPM; hence, the results from the CLPM are easier to replicate, which may be a reason to prefer this model."}

On page 1028, @orth_testing_2021 state that "For the CLPM, the structural coefficients were much more consistent compared to the RI-CLPM, both across and within samples, which is important with regard to replicability of research findings (Asendorf et al., 2013). Even if theoretical consideration have priority over replicability in model selection, replicability of estimates is---other things being equal---an important criterion of the quality of statistical models."

When the goal is prediction, this may indeed be an important consideration. However, when the goal is to gain insight in the underlying mechanism, we should not prefer a model simply based on its ability to replicate results: Replicating biased results is only giving us false confidence in erroneous conclusions. 

Instead, we should consider which model seems more reasonable (e.g., do we believe there may be unobserved, stable confounding that plays a role in our measurements?), and which model provides a better description of the data (e.g., comparing competing models through the use of the chi-square difference test, or information criteria).

The larger standard errors associated with the RI-CLPM imply that if we want to have the higher precision and/or increase replicability, we need to obtain data from larger samples and/or at more waves.
:::
